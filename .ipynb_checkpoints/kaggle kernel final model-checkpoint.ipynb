{
  "cells": [
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cd9bf7670bde0c6f0b0f08edfbf6c3d65ac35b23"
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\n#train = pd.read_csv('../input/processed-data/cleaned_traindata.csv')\ntrain = pd.read_csv('../input/newdata/somenew_data.csv')\nxytrain, xyval = train_test_split(train, test_size=0.2)\nXYTrain = xytrain.applymap(str)\nXYValid = xyval.applymap(str)\nX_Train = XYTrain['question_text'].values\nY_Train = XYTrain['target'].values\nX_Valid = XYValid['question_text'].values\nY_Valid = XYValid['target'].values",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "97f0c7a66ceb8aa102e578844d53854d978104fd"
      },
      "cell_type": "code",
      "source": "from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n\nnum_words = 60000\nseq_length = 75\nembedding_dim = 300\n \ntokenizer = Tokenizer(num_words = num_words)\ntokenizer.fit_on_texts(list(X_Train))\ntoken_train = tokenizer.texts_to_sequences(X_Train)\ntoken_valid = tokenizer.texts_to_sequences(X_Valid)\nxtrain = pad_sequences(token_train, maxlen = seq_length)\nxvalid = pad_sequences(token_valid, maxlen = seq_length)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f20bc94e93c6e570c40cd9f62c8f03bffdcbe626"
      },
      "cell_type": "code",
      "source": "embeddings = dict()\nwith open('../input/quora-insincere-questions-classification/embeddings/paragram_300_sl999/paragram_300_sl999.txt', 'r', errors = 'ignore', encoding='utf8') as vocab:\n    for line in vocab:\n        indices = line.strip().split(' ')\n        #first column\n        word = indices[0]\n        coefs = np.asarray(indices[1:], dtype='float32')\n        embeddings[word] = coefs",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d3402c83082f52b3ee28dd642403a422772cea35"
      },
      "cell_type": "code",
      "source": "GLembeddings = dict()\nwith open('../input/quora-insincere-questions-classification/embeddings/glove.840B.300d/glove.840B.300d.txt', 'r', errors = 'ignore', encoding='utf8') as vocab:\n    for line in vocab:\n        indices = line.strip().split(' ')\n        #first column\n        word = indices[0]\n        coefs = np.asarray(indices[1:], dtype='float32')\n        GLembeddings[word] = coefs",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7a1a99953bf18b28df9b37ccd796ea0f545d66e9"
      },
      "cell_type": "code",
      "source": "word_index = tokenizer.word_index\nwords = min(num_words, len(word_index))\nembedding_matrix = np.zeros((words, embedding_dim))\nfor word, i in word_index.items():\n    if i > num_words-1: \n        continue\n    else:\n        embedding_vector = GLembeddings.get(word)\n        if embedding_vector is not None: \n            embedding_matrix[i] = embedding_vector",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f3cf61451ba65a172fe0cd6c653ed61e0276db63"
      },
      "cell_type": "code",
      "source": "embedding_matrix_1 = np.zeros((words, embedding_dim))\nfor word, i in word_index.items():\n    if i > num_words-1: \n        continue\n    else:\n        embedding_vector = embeddings.get(word)\n        if embedding_vector is not None: \n            embedding_matrix_1[i] = embedding_vector",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7d4007997d1b38a738fb5360aea083d15b9fa4e1"
      },
      "cell_type": "markdown",
      "source": "Embedding + LSTM + max avg pool"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "93b861102b9d97af28c8522f82e12ad048179325"
      },
      "cell_type": "code",
      "source": "from keras.layers import *\nfrom keras.models import Model\nfrom keras.optimizers import *\n\ndef get_model_v0(lr=0.005):\n    inputs = Input(shape=(seq_length,))\n    x = Embedding(num_words, embedding_dim, weights = [embedding_matrix], input_length = seq_length, trainable=False)(inputs)\n    x = SpatialDropout1D(0.2)(x)\n    x = Bidirectional(CuDNNLSTM(80, return_sequences=True))(x)\n    max_pool = GlobalMaxPooling1D()(x)\n    avg_pool = GlobalAveragePooling1D()(x)\n    conc = concatenate([max_pool, avg_pool])\n    outputs = Dense(64, activation=\"relu\")(conc)\n    outputs = Dense(1, activation='sigmoid')(outputs)\n    model = Model(inputs=inputs, outputs=outputs)\n    optimizer = Adam(lr=lr)\n    model.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])\n    print(model.summary())\n    return model",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f3419a2c08e3fd1f503b48c96c5fe1574b8b858e"
      },
      "cell_type": "code",
      "source": "from keras.layers import *\nfrom keras.models import Model\nfrom keras.optimizers import *\n\ndef get_model_v2(lr=0.005):\n    inputs = Input(shape=(seq_length,))\n    a = Embedding(num_words, embedding_dim, weights = [embedding_matrix], input_length = seq_length, trainable=False)(inputs)\n    b = Embedding(num_words, embedding_dim, weights = [embedding_matrix_1], input_length = seq_length, trainable = False)(inputs)\n    x = concatenate([a,b])\n    x = SpatialDropout1D(0.2)(x)\n    x = Bidirectional(CuDNNLSTM(80, return_sequences=True))(x)\n    max_pool = GlobalMaxPooling1D()(x)\n    outputs = Dense(64, activation=\"elu\")(max_pool)\n    outputs = Dense(1, activation='sigmoid')(outputs)\n    model = Model(inputs=inputs, outputs=outputs)\n    optimizer = Adam(lr=lr)\n    model.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])\n    print(model.summary())\n    return model",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1a87bf0e9074294c47a5a06af1e7a26b8fbf6720"
      },
      "cell_type": "code",
      "source": "from keras.layers import *\nfrom keras.models import Model\nfrom keras.optimizers import *\n\ndef get_model_v1(lr=0.005):\n    inputs = Input(shape=(seq_length,))\n    a = Embedding(num_words, embedding_dim, weights = [embedding_matrix], input_length = seq_length, trainable=False)(inputs)\n    b = Embedding(num_words, embedding_dim, weights = [embedding_matrix_1], input_length = seq_length, trainable = False)(inputs)\n    x = concatenate([a,b])\n    x = Dropout(0.2)(x)\n    conv_1 = Conv1D(128, 5, activation = \"relu\", padding = \"same\")(x)\n    conv_2 = Conv1D(128, 4, activation = \"relu\", padding = \"same\")(x)\n    conv_3 = Conv1D(128, 3, activation = \"relu\", padding = \"same\")(x)\n    conv_4 = Conv1D(128, 2, activation = \"relu\", padding = \"same\")(x)\n    z = concatenate([conv_1, conv_2, conv_3, conv_4])\n    max_pool = GlobalMaxPooling1D()(z)\n    avg_pool = GlobalAveragePooling1D()(z)\n    y = concatenate([max_pool, avg_pool])\n    outputs = Dense(64, activation=\"elu\")(y)\n    outputs = Dense(1, activation='sigmoid')(outputs)\n    model = Model(inputs=inputs, outputs=outputs)\n    optimizer = Adam(lr=lr)\n    model.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])\n    print(model.summary())\n    return model",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "34743d952c2154ba77c2addb2a9bf786108e667f"
      },
      "cell_type": "code",
      "source": "def get_model_v3(lr=0.005):\n    inputs = Input(shape=(seq_length,))\n    a = Embedding(num_words, embedding_dim, weights = [embedding_matrix], input_length = seq_length, trainable=False)(inputs)\n    b = Embedding(num_words, embedding_dim, weights = [embedding_matrix_1], input_length = seq_length, trainable = False)(inputs)\n    x = concatenate([a,b])\n    x = SpatialDropout1D(0.2)(x)\n    x = CuDNNLSTM(128, return_sequences=True)(x)\n    x = CuDNNLSTM(64, return_sequences= True)(x)\n    max_pool = GlobalMaxPooling1D()(x)\n    avg_pool = GlobalAveragePooling1D()(x)\n    y = concatenate([max_pool, avg_pool])\n    outputs = Dense(64, activation='relu')(y)\n    outputs = Dropout(0.1)(outputs)\n    outputs = Dense(1, activation='sigmoid')(outputs)\n    model = Model(inputs=inputs, outputs=outputs)\n    optimizer = Adam(lr=lr)\n    model.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])\n    print(model.summary())\n    return model",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ba6c748b18218756cd99fc73c9ea833fcafcead5"
      },
      "cell_type": "code",
      "source": "model = get_model_v2()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "74884fedcbd48907bf8495802446e91f8632e862"
      },
      "cell_type": "code",
      "source": "yvalid = [float(i) for i in Y_Valid]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fa503dab4898c05d256c1a950f82483d7ded71ed"
      },
      "cell_type": "code",
      "source": "history = model.fit(xtrain,Y_Train,batch_size=370,epochs=15, verbose = 1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b74ac75402e78f27b6af6bbaf1cd9a5ab7658eb1"
      },
      "cell_type": "code",
      "source": "model.save('model-CNN-para-v1.h5')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2d0d726a0a9d7362eaac022cfd26e13dbe171f9d"
      },
      "cell_type": "code",
      "source": "pred = model.predict(xvalid, verbose = True)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "daa5bbd2e9f06ec7475b98f82e1e4abb568a929f"
      },
      "cell_type": "code",
      "source": "binary = np.round(pred)\nY_Valid = [float(i) for i in Y_Valid]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "24bcaf19ad77a83054a4c185f0fc962404256857"
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import confusion_matrix,classification_report, f1_score\n\nprint(confusion_matrix(Y_Valid,binary))\nprint(classification_report(Y_Valid, binary))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c72aff931fa9dab95c56a063a4f1c376187a2f31"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}